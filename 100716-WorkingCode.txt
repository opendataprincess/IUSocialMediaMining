#from CMD window, "pip install pyquery"

import got3 
import pandas as pd

tweetCriteria = got3.manager.TweetCriteria()
tweetCriteria.setQuerySearch("escasez geocode:10.4806,-66.9036,10km")
tweetCriteria.setSince("2014-12-01")
tweetCriteria.setUntil("2016-09-30")
escasez_c_tweets = got3.manager.TweetManager.getTweets(tweetCriteria)
for x in escasez_c_tweets:
    print(x.text, x.date, x.favorites, x.retweets)
    print("*"* 50)

for tweet in escasez_c_tweets:
    tid = tweet.id
    #date_created = tweet.created_at
    date_created = tweet.date
    #favorite_count = tweet.favorite_count
    favorite_count = tweet.favorites
    #retweet_count = tweet.retweet_count
    retweet_count = tweet.retweets
    text = tweet.text
    #escasez_c_tweets = [tid, hour_created, text, favorite_count, retweet_count]
    # escasez_c_tweets is an existing object - it's the list of tweet objects
    # from GOT. We don't want to assign the data to escasez_c_tweets
    this_tweet_extracted_information = [tid, date_created, text, favorite_count, retweet_count]
    # tweetCriteria.append(escasez_c_tweets)
    # tweetCriteria is the tweet criteria object, not a list we can append to
    # I made an empty list above (line 2) the for loop to contain our tweet extracted info
    extracted_data.append(this_tweet_extracted_information)

df.shape
df

subset = df[ df['favorite_count'] > 5]
subset = df[ df['retweet_count'] > 5]
subset.shape
subset

#Natural Language ProcessingS#Stopwordsfrom sklearn.feature_extraction import textmy_stop_words = text.ENGLISH_STOP_WORDS.union(él,ésta,éstas,éste,éstos,última,últimas,último,últimos,a,añadió,aún,actualmente,adelante,además,afirmó,agregó,ahí,ahora,al,algún,algo,alguna,algunas,alguno,algunos,alrededor,ambos,ante,anterior,antes,apenas,aproximadamente,aquí,así,aseguró,aunque,ayer,bajo,bien,buen,buena,buenas,bueno,buenos,cómo,cada,casi,cerca,cierto,cinco,comentó,como,con,conocer,consideró,considera,contra,cosas,creo,cual,cuales,cualquier,cuando,cuanto,cuatro,cuenta,da,dado,dan,dar,de,debe,deben,debido,decir,dejó,del,demás,dentro,desde,después,dice,dicen,dicho,dieron,diferente,diferentes,dijeron,dijo,dio,donde,dos,durante,e,ejemplo,el,ella,ellas,ello,ellos,embargo,en,encuentra,entonces,entre,era,eran,es,esa,esas,ese,eso,esos,está,están,esta,estaba,estaban,estamos,estar,estará,estas,este,esto,estos,estoy,estuvo,ex,existe,existen,explicó,expresó,fin,fue,fuera,fueron,gran,grandes,ha,había,habían,haber,habrá,hace,hacen,hacer,hacerlo,hacia,haciendo,han,hasta,hay,haya,he,hecho,hemos,hicieron,hizo,hoy,hubo,igual,incluso,indicó,informó,junto,la,lado,las,le,les,llegó,lleva,llevar,lo,los,luego,lugar,más,manera,manifestó,mayor,me,mediante,mejor,mencionó,menos,mi,mientras,misma,mismas,mismo,mismos,momento,mucha,muchas,mucho,muchos,muy,nada,nadie,ni,ningún,ninguna,ningunas,ninguno,ningunos,no,nos,nosotras,nosotros,nuestra,nuestras,nuestro,nuestros,nueva,nuevas,nuevo,nuevos,nunca,o,ocho,otra,otras,otro,otros,para,parece,parte,partir,pasada,pasado,pero,pesar,poca,pocas,poco,pocos,podemos,podrá,podrán,podría,podrían,poner,por,porque,posible,próximo,próximos,primer,primera,primero,primeros,principalmente,propia,propias,propio,propios,pudo,pueda,puede,pueden,pues,qué,que,quedó,queremos,quién,quien,quienes,quiere,realizó,realizado,realizar,respecto,sí,sólo,se,señaló,sea,sean,según,segunda,segundo,seis,ser,será,serán,sería,si,sido,siempre,siendo,siete,sigue,siguiente,sin,sino,sobre,sola,solamente,solas,solo,solos,son,su,sus,tal,también,tampoco,tan,tanto,tenía,tendrá,tendrán,tenemos,tener,tenga,tengo,tenido,tercera,tiene,tienen,toda,todas,todavía,todo,todos,total,tras,trata,través,tres,tuvo,un,una,unas,uno,unos,usted,va,vamos,van,varias,varios,veces,ver,vez,y,ya,yo)

vectorizer = TfidVectorizer(analyzer=u'word', max_df=0.95, lowercase=True,stop_words=set(my_stop_words),max_features=15000
X= vectorizer.fit_transform(text)

#Remove URLs from Tweets
#Stem Text with Snowball
from nltk import word_tokenizerfrom nltk.stem 
import SnowballStemmerstemmer = SnowballStemmer('spanish')stemmer.stem('df')


tenía
tendrá
tendrán
tenemos
tener
tenga
tengo
tenido
tercera
tiene
tienen
toda
todas
todavía
todo
todos
total
tras
trata
través
tres
tuvo
un
una
unas
uno
unos
usted
va
vamos
van
varias
varios
veces
ver
vez
y
ya
yo

#Stem Text with Snowball
from nltk import word_tokenizer
from nltk.stem import SnowballStemmer

stemmer = SnowballStemmer('spanish')
stemmer.stem('df')


#Visualizations

tweets_hambre_Caracas = hambre_c_tweets.value_counts()


fig, ax = plt.subplots()
ax.tick_params(axis='x', labelsize=15)
ax.tick_params(axis='y', labelsize=10)
ax.set_xlabel('Hambre', fontsize=15)
ax.set_ylabel("Number of tweets', fontsize=15)
ax.set_title('Hambre in Venezuela, December 2014 - September 2016, fontsize=15,fontweight='bold')
tweets_hambre_Caracas.plot(ax=ax, kind='bar', color='purple')

# Need to initialize an empty list to collect tweets
extracted_data = [

#NLP Lowercase
tweet_texts =[x.lower() for x in tweet_texts]
tweet_texts[2]

#Split strings into list of individual words
tweet_texts = [x.split() for x in tweet_texts]
tweet_texts[:5]

from collections import Counter
word_frequency = Counter()
for x in tweet_texts: 
    word_frequency.update(x)
word_frequency

word_frequency.most_common(20)
top20 = word_frequency.most_comm(20)
top20
top_words = [x[0] for x in top20]
top_frequencies = [x[1] for x intop20]
#verify separation of data
print(top_words[:5])
print("*"*50)
print(top_frequencies[:5])
x_positions = np.arange(20)
x_positions

plt.bar(x_positions, top_frequencies)
plt.xticks(x_positions, top_words, rotation = 90)
#correct offsetting of words in barchart--move the word to the right
plt.bar(x_positions, top_frequencies)
plt.xsticks(x_positions+0.5, top_words, rotation=90)
plt.title("Word Frequency in Most Recent Trump Tweets")
plt.ylabel("Frequency")
plt.show()]
