from sklearn.cross_validation import cross_val_score
#You can use "R2" or "F1" for scoring metric
#This example uses 10 folds

cv_scores = cross_val_score(clf, x_train, y_train, scoring="accuracy", cv=10)
print(cv_scores)
print(np.mean(cv_scores))

#Hyperparameter optimization
k_candidates = np.arange(1, 50, 2)
average_accuracies = []
for k in k_candidates:
    clf = KNeighborsClassifier(n_neighbors=k)
    cv_scores = cross_val_score(clf, x_train, y_train, scoring="accuracy", cv=10)
    average_accuracy = np.mean(cv_scores)
    average_accuracies.append(average_accuracy)

import matplotlib.pyplot as plt
plt.ioff()
plt.plot(k_candidates, average_accuracies)
plt.xlabel("Value of k in kNN")
plt.ylabel("Average 10-fold CV Accuracy")
plt.show()
list(zip(k_candidates, average_accuracies))[6:9]

#17 is the best candidate for k
# if it performs well, we have a good model
#Let's test it's performance in SciKit

from sklearn.metrics import accuracy_score, confusion_matrix
clf = KNeighborsClassifier(n_neighbors=17)
clf.fit(x_train, y_train)
#only use test data as a final test to see if we have a good model
y_pred = clf.predict(x_test)
print("Final Test Set Accuracy:")
print(accuracy_score(y_test, y_pred))

confusion_matrix(y_test,y_pred)
#Only mislabeled 1 instance [0,14,1] of 2nd feature

#Use cross validation for any algorithm that has hyperparameters
